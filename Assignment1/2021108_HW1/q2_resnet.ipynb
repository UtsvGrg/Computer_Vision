{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mutsav21108\u001b[0m (\u001b[33mutsv-grg\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/iiitd/Desktop/cv/wandb/run-20240218_202205-nnhkb5io</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/utsv-grg/cv_ass1/runs/nnhkb5io' target=\"_blank\">Q2_Resnet_normalized</a></strong> to <a href='https://wandb.ai/utsv-grg/cv_ass1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/utsv-grg/cv_ass1' target=\"_blank\">https://wandb.ai/utsv-grg/cv_ass1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/utsv-grg/cv_ass1/runs/nnhkb5io' target=\"_blank\">https://wandb.ai/utsv-grg/cv_ass1/runs/nnhkb5io</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "wandb.init(\n",
    "    project=\"cv_ass1\", \n",
    "    name=f\"Q2_Resnet\", \n",
    "    config={\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"Russian Wildlife Dataset\",\n",
    "    \"epochs\": 10,\n",
    "    })\n",
    "\n",
    "config = wandb.config   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'black_bear': 0, 'people': 1, 'birds': 2, 'dog': 3, 'brown_bear': 4, 'roe_deer': 5, 'wild_boar': 6, 'amur_tiger': 7, 'amur_leopard': 8, 'sika_deer': 9}\n",
    "target_size = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "weights = ResNet18_Weights.DEFAULT\n",
    "preprocess = weights.transforms()\n",
    "model = resnet18(weights=weights)\n",
    "model.fc = nn.Linear(512,10,bias=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RussianWildlifeDataset(Dataset):\n",
    "\n",
    "    def __init__(self, img_dir):\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.data_list = []\n",
    "        for label in os.listdir(self.img_dir):\n",
    "            for file in os.listdir(os.path.join(self.img_dir,label)):\n",
    "                self.data_list.append((file,label))\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        file_name, label = self.data_list[idx]\n",
    "        img_path = os.path.join(self.img_dir, label, file_name)\n",
    "        img = read_image(img_path)\n",
    "        img = preprocess(img)\n",
    "        return img, label_map[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12825\n"
     ]
    }
   ],
   "source": [
    "data = RussianWildlifeDataset('data')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8977 1282 2566\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.7 * len(data))\n",
    "val_size = int(0.1 * len(data))\n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "train_set, val_set, test_set = random_split(data, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=8)\n",
    "\n",
    "print(len(train_set), len(val_set), len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training\n",
      "Training for epoch:  0\n",
      "EPOCH: 0\n",
      "Average train loss: 1.0556671603562984\n",
      "Average val loss: 0.9650225795450664\n",
      "Training for epoch:  1\n",
      "EPOCH: 1\n",
      "Average train loss: 0.6905027204160149\n",
      "Average val loss: 0.7942034261567252\n",
      "Training for epoch:  2\n",
      "EPOCH: 2\n",
      "Average train loss: 0.5064740311486501\n",
      "Average val loss: 0.7844162072759078\n",
      "Training for epoch:  3\n",
      "EPOCH: 3\n",
      "Average train loss: 0.4022998444418958\n",
      "Average val loss: 0.735050210640544\n",
      "Training for epoch:  4\n",
      "EPOCH: 4\n",
      "Average train loss: 0.31231757969403945\n",
      "Average val loss: 0.7088772805318946\n",
      "Training for epoch:  5\n",
      "EPOCH: 5\n",
      "Average train loss: 0.25202702022164214\n",
      "Average val loss: 0.597333097719543\n",
      "Training for epoch:  6\n",
      "EPOCH: 6\n",
      "Average train loss: 0.221102187409997\n",
      "Average val loss: 0.6825073936155864\n",
      "Training for epoch:  7\n",
      "EPOCH: 7\n",
      "Average train loss: 0.1580125565561367\n",
      "Average val loss: 0.6347895759446103\n",
      "Training for epoch:  8\n",
      "EPOCH: 8\n",
      "Average train loss: 0.11987939808874372\n",
      "Average val loss: 0.7144115276279903\n",
      "Training for epoch:  9\n",
      "EPOCH: 9\n",
      "Average train loss: 0.12377726376479399\n",
      "Average val loss: 0.7709608546214267\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 10\n",
    "save_loss = 99999\n",
    "\n",
    "print(\"Started Training\")\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    print('Training for epoch: ', epoch)\n",
    "\n",
    "    model.train()\n",
    "    tloss = 0\n",
    "    tstep = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        img, label = data\n",
    "        inputs = img.to(device)\n",
    "        labels = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.squeeze(1)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        train_loss =  criterion(outputs, labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        tstep+=1\n",
    "        tloss += train_loss.item()\n",
    "\n",
    "    tstep+=1\n",
    "    print('EPOCH:',epoch)\n",
    "    print('Average train loss:', tloss/tstep)\n",
    "\n",
    "    model.eval()\n",
    "    vloss = 0\n",
    "    vstep = 0\n",
    "\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        img, label = data\n",
    "        inputs = img.to(device)\n",
    "        labels = label.to(device)\n",
    "\n",
    "        inputs = inputs.squeeze(1)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        val_loss =  criterion(outputs, labels)\n",
    "        vstep+=1\n",
    "        vloss += val_loss.item()\n",
    "\n",
    "    vstep+=1\n",
    "    print('Average val loss:', vloss/vstep)\n",
    "    if(vloss/vstep<save_loss):\n",
    "        save_loss = vloss/vstep\n",
    "        state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "        torch.save(state, 'q2_resnet_best.pt')  \n",
    "\n",
    "    log_metric = {\"Epoch\":epoch, \"Train Loss\": tloss/tstep, \"Val Loss\": vloss/vstep}\n",
    "    wandb.log(log_metric)\n",
    "        \n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "torch.save(state, 'q2_resnet.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train loss keeps on reducing on training after each epoch which is expected, but after epoch 4. The val loss starts increasing which increase to 2.03. Thus the model is overtrained now\n",
    "Only keeping the train limited to 5 epochs would have been ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In case best model is to be runned.\n",
    "model = resnet18()\n",
    "model.fc = nn.Linear(512,10,bias=True)\n",
    "state_dict = torch.load('q2_resnet_best.pt')\n",
    "model.load_state_dict(state_dict['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Testing\n",
      "Finished Testing\n"
     ]
    }
   ],
   "source": [
    "print(\"Started Testing\")\n",
    "\n",
    "test_labels = []\n",
    "test_predictions = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        img, labels = data\n",
    "        test_labels.extend(labels.numpy())\n",
    "\n",
    "        inputs = img.to(device)\n",
    "        inputs = inputs.squeeze(1)\n",
    "        \n",
    "        outputs = model(inputs).argmax(dim=1)\n",
    "        test_predictions.extend(outputs.numpy())\n",
    "        \n",
    "print(\"Finished Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8347622759158223\n",
      "F1 Score:  0.8337948738866295\n",
      "[[134   0   5   4  52   1  11   1   1   2]\n",
      " [  0 247   7  11   3   8   2   4   2   8]\n",
      " [  3   2 267  18   3   1   6   3   1   5]\n",
      " [  4   2   7 195   5   7   6   7   1  16]\n",
      " [ 26   1   5   5 211   2  16   1   2   1]\n",
      " [  0   0   1   2   1 194   2   0   0   9]\n",
      " [  1   0   3   3   8   6 243   0   0   4]\n",
      " [  0   0   5  11   6   1   3 195   3   5]\n",
      " [  0   0   1   2   3   0   2   0 219   0]\n",
      " [  1   2  10  10   5  24   9   3   0 237]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "test_predictions = np.array(test_predictions)\n",
    "\n",
    "\n",
    "correct = (test_labels==test_predictions).sum()\n",
    "total = len(test_predictions)\n",
    "\n",
    "acc = correct/total\n",
    "f1score = f1_score(test_labels,test_predictions,average='macro')\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 Score: \", f1score)\n",
    "\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "# wandb.log({\"Accuracy\":acc, \"F1 Score\":f1score})\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.show(plt)\n",
    "# wandb.log({\"Confusion Matrix\": wandb.Image(plt)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁</td></tr><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>F1 Score</td><td>▁</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>Val Loss</td><td>█▅▅▄▃▁▃▂▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.81645</td></tr><tr><td>Epoch</td><td>9</td></tr><tr><td>F1 Score</td><td>0.81725</td></tr><tr><td>Train Loss</td><td>0.12378</td></tr><tr><td>Val Loss</td><td>0.77096</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Q2_Resnet_normalized</strong> at: <a href='https://wandb.ai/utsv-grg/cv_ass1/runs/nnhkb5io' target=\"_blank\">https://wandb.ai/utsv-grg/cv_ass1/runs/nnhkb5io</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240218_202205-nnhkb5io/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
