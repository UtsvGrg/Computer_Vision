{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import v2\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_map = {'black_bear': 0, 'people': 1, 'birds': 2, 'dog': 3, 'brown_bear': 4, 'roe_deer': 5, 'wild_boar': 6, 'amur_tiger': 7, 'amur_leopard': 8, 'sika_deer': 9}\n",
    "target_size = (224,224)\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.RandomResizedCrop(size=target_size, antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RussianWildlifeDataset(Dataset):\n",
    "\n",
    "    def __init__(self, img_dir):\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.data_list = []\n",
    "        for label in os.listdir(self.img_dir):\n",
    "            for file in os.listdir(os.path.join(self.img_dir,label)):\n",
    "                self.data_list.append((file,label))\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        file_name, label = self.data_list[idx]\n",
    "        img_path = os.path.join(self.img_dir, label, file_name)\n",
    "\n",
    "        img = torch.from_numpy(cv2.imread(img_path))\n",
    "        img = img.permute(2, 0, 1)\n",
    "        img = img/255\n",
    "        img = transforms(img)\n",
    "        return img.float(), label_map[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12825\n"
     ]
    }
   ],
   "source": [
    "data = RussianWildlifeDataset('data')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8977 1282 2566\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.7 * len(data))\n",
    "val_size = int(0.1 * len(data))\n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "train_set, val_set, test_set = random_split(data, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=8)\n",
    "\n",
    "print(len(train_set), len(val_set), len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mutsav21108\u001b[0m (\u001b[33mutsv-grg\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/iiitd/Desktop/cv/wandb/run-20240218_230902-c4ilo3pi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/utsv-grg/cv_ass1/runs/c4ilo3pi' target=\"_blank\">Q2_CNN_AUG</a></strong> to <a href='https://wandb.ai/utsv-grg/cv_ass1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/utsv-grg/cv_ass1' target=\"_blank\">https://wandb.ai/utsv-grg/cv_ass1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/utsv-grg/cv_ass1/runs/c4ilo3pi' target=\"_blank\">https://wandb.ai/utsv-grg/cv_ass1/runs/c4ilo3pi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "wandb.init(\n",
    "    project=\"cv_ass1\", \n",
    "    name=f\"Q2_CNN_AUG\", \n",
    "    config={\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"Russian Wildlife Dataset\",\n",
    "    \"epochs\": 10,\n",
    "    })\n",
    "\n",
    "config = wandb.config   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "  \n",
    "  def __init__(self, num_classes):\n",
    "\n",
    "    super(CNN, self).__init__()\n",
    "\n",
    "    self.conv1 = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, padding=1, stride=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=4, stride=4)\n",
    "    )\n",
    "\n",
    "    self.conv2 = nn.Sequential(\n",
    "        nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "\n",
    "    self.conv3 = nn.Sequential(\n",
    "        nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.fc = nn.Linear(25088, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CNN(10) # Assuming 10 classes\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training\n",
      "Training for epoch:  0\n",
      "EPOCH: 0\n",
      "Average train loss: 2.069390412763501\n",
      "EPOCH: 0\n",
      "Average val loss: 1.8633783573196048\n",
      "Training for epoch:  1\n",
      "EPOCH: 1\n",
      "Average train loss: 1.8511972144140418\n",
      "EPOCH: 1\n",
      "Average val loss: 1.721048803556533\n",
      "Training for epoch:  2\n",
      "EPOCH: 2\n",
      "Average train loss: 1.7062070107629113\n",
      "EPOCH: 2\n",
      "Average val loss: 1.5579820956502641\n",
      "Training for epoch:  3\n",
      "EPOCH: 3\n",
      "Average train loss: 1.6200160878769896\n",
      "EPOCH: 3\n",
      "Average val loss: 1.5205740815117246\n",
      "Training for epoch:  4\n",
      "EPOCH: 4\n",
      "Average train loss: 1.5514198503595718\n",
      "EPOCH: 4\n",
      "Average val loss: 1.5481050411860149\n",
      "Training for epoch:  5\n",
      "EPOCH: 5\n",
      "Average train loss: 1.4719773197004982\n",
      "EPOCH: 5\n",
      "Average val loss: 1.3769831543877011\n",
      "Training for epoch:  6\n",
      "EPOCH: 6\n",
      "Average train loss: 1.4088380347329674\n",
      "EPOCH: 6\n",
      "Average val loss: 1.3600028923579626\n",
      "Training for epoch:  7\n",
      "EPOCH: 7\n",
      "Average train loss: 1.3842791424575427\n",
      "EPOCH: 7\n",
      "Average val loss: 1.467344548021044\n",
      "Training for epoch:  8\n",
      "EPOCH: 8\n",
      "Average train loss: 1.358332154175914\n",
      "EPOCH: 8\n",
      "Average val loss: 1.2786300409407843\n",
      "Training for epoch:  9\n",
      "EPOCH: 9\n",
      "Average train loss: 1.3291073557755626\n",
      "EPOCH: 9\n",
      "Average val loss: 1.285435716311137\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "n_epoch = config.epochs\n",
    "save_loss = 99999\n",
    "\n",
    "print(\"Started Training\")\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    print('Training for epoch: ', epoch)\n",
    "\n",
    "    model.train()\n",
    "    tloss = 0\n",
    "    tstep = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        img, label = data\n",
    "        inputs = img.to(device)\n",
    "        labels = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.squeeze(1)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        train_loss =  criterion(outputs, labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        tstep+=1\n",
    "        tloss += train_loss.item()\n",
    "\n",
    "    tstep+=1\n",
    "    print('EPOCH:',epoch)\n",
    "    print('Average train loss:', tloss/tstep)\n",
    "\n",
    "    model.eval()\n",
    "    vloss = 0\n",
    "    vstep = 0\n",
    "\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        img, label = data\n",
    "        inputs = img.to(device)\n",
    "        labels = label.to(device)\n",
    "\n",
    "        inputs = inputs.squeeze(1)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        val_loss =  criterion(outputs, labels)\n",
    "        vstep+=1\n",
    "        vloss += val_loss.item()\n",
    "\n",
    "    vstep+=1\n",
    "    print('EPOCH:',epoch)\n",
    "    print('Average val loss:', vloss/vstep)\n",
    "    if(vloss/vstep<save_loss):\n",
    "        save_loss = vloss/vstep\n",
    "        state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "        torch.save(state, 'q2_cnn_aug_best.pt')  \n",
    "\n",
    "    log_metric = {\"Epoch\":epoch, \"Train Loss\": tloss/tstep, \"Val Loss\": vloss/vstep}\n",
    "    wandb.log(log_metric)\n",
    "        \n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "torch.save(state, 'q2_cnn_aug.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train loss keeps on reducing on training after each epoch which is expected. And because we have introduced data augmentation the overfitting is stopped. The val decreases continously.\n",
    "One can also see the train loss is also reducing slowly then without augmentation as it sees more of new training data.\n",
    "Actually it is underfitted and can see more training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In case best model is to be runned.\n",
    "# model = CNN(10)\n",
    "# state_dict = torch.load('q2_cnn_best.pt')\n",
    "# model.load_state_dict(state_dict['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Testing\n",
      "Finished Testing\n"
     ]
    }
   ],
   "source": [
    "print(\"Started Testing\")\n",
    "\n",
    "test_labels = []\n",
    "test_predictions = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        img, labels = data\n",
    "        test_labels.extend(labels.numpy())\n",
    "\n",
    "        inputs = img.to(device)\n",
    "        inputs = inputs.squeeze(1)\n",
    "        \n",
    "        outputs = model(inputs).argmax(dim=1)\n",
    "        test_predictions.extend(outputs.numpy())\n",
    "        \n",
    "print(\"Finished Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5354637568199533\n",
      "F1 Score:  0.5359180307504628\n",
      "[[ 94   3   1   8  60   7  12   0   1  16]\n",
      " [  4 187  15  17  11  12   2   5   4  16]\n",
      " [  5  33 205  20  23  12  12   4  16  11]\n",
      " [ 18  16  22  76  19  29  13  12   5  57]\n",
      " [ 44   9   3   6 125  26  15   1   1  11]\n",
      " [  7  10   5  10  14 134   5   4   1  50]\n",
      " [ 37   5   8  13  50  27 162   1   9  13]\n",
      " [  7   5  12   4   4  20   1 112  13  15]\n",
      " [  4   1  17   5   6  12   3  18 128   8]\n",
      " [ 12  21  17  11  18  35   8   7   2 151]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "test_predictions = np.array(test_predictions)\n",
    "\n",
    "\n",
    "correct = (test_labels==test_predictions).sum()\n",
    "total = len(test_predictions)\n",
    "\n",
    "acc = correct/total\n",
    "f1score = f1_score(test_labels,test_predictions,average='macro')\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 Score: \", f1score)\n",
    "\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "wandb.log({\"Accuracy\":acc, \"F1 Score\":f1score})\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAWEElEQVR4nO3df4zUhf3n8feyyLDiwhexoJyg1PSC/FBB0FMuto1EY8TU77exNcEchznbaxcFSUyhjRpjYaWphEQsiGmV+1YUL43Rmmjj0Si1lYCgnqat1Jiv3egBmnq7C7QL7sz94bnfL98RuwP75jOzPh7J/MFkhs8rs8s+97OzzDRVKpVKAMAAG1L0AAAGJ4EBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFENP9AHL5XK899570draGk1NTSf68AAch0qlEt3d3TF+/PgYMuSzz1FOeGDee++9mDBhwok+LAADqKOjI84888zPvM0JD0xra2tERNz8P16I0smnnOjDH9XSL59T9IQqQ+rwBK/no3LRE6rsfOfDoidUmXXW6KInVOntrb9XhTp5+An/EvR31eOrZ3X/9aOiJ/Tp7u6OmVMm9X0t/ywn/KP7yY/FSiefEqUR9ROYkSNHFj2hisD0z4hT6ucf3yfq8fPpozoMzAiB6Z+T6u9zvD9PcXiSH4AUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASDFMQXm/vvvj7PPPjuGDx8eF198cWzfvn2gdwHQ4GoOzObNm2Pp0qVx5513xq5du+L888+PK6+8Mvbt25exD4AGVXNgVq9eHTfddFMsXLgwpkyZEuvXr4+TTz45fvazn2XsA6BB1RSYQ4cOxc6dO2Pu3Ln/+hcMGRJz586Nl1566VPv09PTE11dXUdcABj8agrMBx98EL29vTFu3Lgjrh83blzs2bPnU+/T3t4eo0aN6rt4N0uAz4f03yJbvnx5dHZ29l06OjqyDwlAHajp7eROO+20aG5ujr179x5x/d69e+P000//1PuUSqUolUrHvhCAhlTTGcywYcPiwgsvjC1btvRdVy6XY8uWLXHJJZcM+DgAGlfNb4i9dOnSWLBgQcyaNSsuuuiiWLNmTRw4cCAWLlyYsQ+ABlVzYL75zW/G+++/H3fccUfs2bMnLrjggnj22WernvgH4POt5sBERCxatCgWLVo00FsAGES8FhkAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNAimN6LbKBcOtlX4yRI0cWdfgqp12zuugJVf7lf95S9IQq5Uql6AlVLjxrdNETqnzUW3+PU8uw5qInVDn8UbnoCVWamopeMHg4gwEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBha1IErlY8v9eKVh/970ROqnP3lW4ueUOWtX99b9IQqB/72UdETqowoFfZP66j+eqi36AlVSifV3/e4B3rq73Ea2txU9IQ+tWypv48uAIOCwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMAClqCkx7e3vMnj07WltbY+zYsXHttdfGm2++mbUNgAZWU2BeeOGFaGtri23btsVzzz0Xhw8fjiuuuCIOHDiQtQ+ABlXTuyI9++yzR/z54YcfjrFjx8bOnTvjsssuG9BhADS243rbvc7OzoiIOPXUU496m56enujp6en7c1dX1/EcEoAGccxP8pfL5ViyZEnMmTMnpk2bdtTbtbe3x6hRo/ouEyZMONZDAtBAjjkwbW1t8cYbb8Rjjz32mbdbvnx5dHZ29l06OjqO9ZAANJBj+hHZokWL4umnn46tW7fGmWee+Zm3LZVKUSqVjmkcAI2rpsBUKpW4+eab44knnojnn38+Jk2alLULgAZXU2Da2tpi06ZN8eSTT0Zra2vs2bMnIiJGjRoVLS0tKQMBaEw1PQezbt266OzsjK985Stxxhln9F02b96ctQ+ABlXzj8gAoD+8FhkAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNAiuN6y+Tjsf9vH0XTsI+KOnyV0SOGFT2hyptb7i16QpX/9dbeoidUmful04ueUOUvBw4VPaHKP5x8UtETqvQcLhc9ocrJw5qLnlBl+7/8pegJfQ7s7+73bZ3BAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSDC3qwHs7/xYHysOKOnyVSWNHFD2hyinDC/vwHNU/Tj+z6AlVrvvp9qInVFn3jfOLnlClXCl6QbVThjcXPaEhXDDhH4qe0Ke7q//nJc5gAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQIrjCsw999wTTU1NsWTJkgGaA8BgccyB2bFjRzzwwANx3nnnDeQeAAaJYwrM/v37Y/78+fHggw/G6NGjB3oTAIPAMQWmra0trr766pg7d+7fvW1PT090dXUdcQFg8Kv5PXkfe+yx2LVrV+zYsaNft29vb4+77rqr5mEANLaazmA6Ojpi8eLF8cgjj8Tw4cP7dZ/ly5dHZ2dn36Wjo+OYhgLQWGo6g9m5c2fs27cvZs6c2Xddb29vbN26NdauXRs9PT3R3Nx8xH1KpVKUSqWBWQtAw6gpMJdffnm8/vrrR1y3cOHCmDx5cnzve9+rigsAn181Baa1tTWmTZt2xHUjRoyIMWPGVF0PwOeb/8kPQIqaf4vs33v++ecHYAYAg40zGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUx/1aZMdq0tgRMXLkiKIOX6W3XCl6QpVyHW76qLdc9IQq//xfLix6QpV/XP9S0ROqPHvzfy56QpV6/HfXPKSp6AlV/vR/9hc9oc+B7v5vcQYDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEgxtKgDv/uXv0bn4ZOKOnyVs047uegJVXorlaInVOkt19+mt/ceKHpClX/+r7OLnlDlPy5+ougJVd5e+09FT6jyt8PloidUOWfciKIn9Olu6e33bZ3BAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQ1B+bdd9+NG264IcaMGRMtLS0xffr0ePnllzO2AdDAano/mA8//DDmzJkTX/3qV+OZZ56JL3zhC/GnP/0pRo8enbUPgAZVU2BWrVoVEyZMiIceeqjvukmTJg34KAAaX00/Invqqadi1qxZcd1118XYsWNjxowZ8eCDD37mfXp6eqKrq+uICwCDX02Befvtt2PdunXxpS99KX71q1/Fd77znbjlllti48aNR71Pe3t7jBo1qu8yYcKE4x4NQP2rKTDlcjlmzpwZK1eujBkzZsS3vvWtuOmmm2L9+vVHvc/y5cujs7Oz79LR0XHcowGofzUF5owzzogpU6Yccd25554bf/7zn496n1KpFCNHjjziAsDgV1Ng5syZE2+++eYR1+3evTvOOuusAR0FQOOrKTC33nprbNu2LVauXBlvvfVWbNq0KTZs2BBtbW1Z+wBoUDUFZvbs2fHEE0/Eo48+GtOmTYu777471qxZE/Pnz8/aB0CDqun/wUREzJs3L+bNm5exBYBBxGuRAZBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKSo+bXIBsp/OLUlRo5sKerwDaG3t1L0hCotw5qLnlBl2oT6e4+hzoOHi55Q5e21/1T0hCrf2vy/i55QZfXXpvz9G51g5Tr6UlDLFmcwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUQ4s6cPOQpmge0lTU4avU05ZP7O8pFz2hyrCh9fc9SaXoAZ9i+EnNRU+oUq7DB2rVvHOLnlDl+odfLnpClV/8t4uKntCn56T+fw2ov68WAAwKAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKSoKTC9vb1x++23x6RJk6KlpSXOOeecuPvuu6NSqcPXAQegUDW9H8yqVati3bp1sXHjxpg6dWq8/PLLsXDhwhg1alTccsstWRsBaEA1BeZ3v/tdfO1rX4urr746IiLOPvvsePTRR2P79u0p4wBoXDX9iOzSSy+NLVu2xO7duyMi4rXXXosXX3wxrrrqqqPep6enJ7q6uo64ADD41XQGs2zZsujq6orJkydHc3Nz9Pb2xooVK2L+/PlHvU97e3vcddddxz0UgMZS0xnM448/Ho888khs2rQpdu3aFRs3bowf//jHsXHjxqPeZ/ny5dHZ2dl36ejoOO7RANS/ms5gbrvttli2bFlcf/31ERExffr0eOedd6K9vT0WLFjwqfcplUpRKpWOfykADaWmM5iDBw/GkCFH3qW5uTnK5fKAjgKg8dV0BnPNNdfEihUrYuLEiTF16tR45ZVXYvXq1XHjjTdm7QOgQdUUmPvuuy9uv/32+O53vxv79u2L8ePHx7e//e244447svYB0KBqCkxra2usWbMm1qxZkzQHgMHCa5EBkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApKjptcgG0qHD5eg5XD8v83/wUG/RE6oMbW4qekKVQ7318zH7RD19Hn3i/x48XPSEKuNHDy96QpURpeaiJ1T55bf/U9ETqpz/g2eLntCn3HOw37d1BgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQYuiJPmClUomIiO7urhN96M908FBv0ROqDG1uKnpClWFD6+97kp7D5aInVNn/18NFT6jS1Xyo6AlV6u8zPOKk5vr7HC/3HCx6Qp/yoY+3fPK1/LOc8MB0d3dHRMR5kyed6EMDMEC6u7tj1KhRn3mbpkp/MjSAyuVyvPfee9Ha2hpNTcf+/UtXV1dMmDAhOjo6YuTIkQO4cHDxOPWPx6l/PE79M5gfp0qlEt3d3TF+/PgYMuSzz/ZO+BnMkCFD4swzzxywv2/kyJGD7gOYwePUPx6n/vE49c9gfZz+3pnLJ+rvh40ADAoCA0CKhg1MqVSKO++8M0qlUtFT6prHqX88Tv3jceofj9PHTviT/AB8PjTsGQwA9U1gAEghMACkEBgAUjRsYO6///44++yzY/jw4XHxxRfH9u3bi55UV9rb22P27NnR2toaY8eOjWuvvTbefPPNomfVtXvuuSeamppiyZIlRU+pO++++27ccMMNMWbMmGhpaYnp06fHyy+/XPSsutLb2xu33357TJo0KVpaWuKcc86Ju+++u1+v2TVYNWRgNm/eHEuXLo0777wzdu3aFeeff35ceeWVsW/fvqKn1Y0XXngh2traYtu2bfHcc8/F4cOH44orrogDBw4UPa0u7dixIx544IE477zzip5Sdz788MOYM2dOnHTSSfHMM8/E73//+7j33ntj9OjRRU+rK6tWrYp169bF2rVr4w9/+EOsWrUqfvSjH8V9991X9LTCNOSvKV988cUxe/bsWLt2bUR8/PpmEyZMiJtvvjmWLVtW8Lr69P7778fYsWPjhRdeiMsuu6zoOXVl//79MXPmzPjJT34SP/zhD+OCCy6INWvWFD2rbixbtix++9vfxm9+85uip9S1efPmxbhx4+KnP/1p33Vf//rXo6WlJX7+858XuKw4DXcGc+jQodi5c2fMnTu377ohQ4bE3Llz46WXXipwWX3r7OyMiIhTTz214CX1p62tLa6++uojPqf4V0899VTMmjUrrrvuuhg7dmzMmDEjHnzwwaJn1Z1LL700tmzZErt3746IiNdeey1efPHFuOqqqwpeVpwT/mKXx+uDDz6I3t7eGDdu3BHXjxs3Lv74xz8WtKq+lcvlWLJkScyZMyemTZtW9Jy68thjj8WuXbtix44dRU+pW2+//XasW7culi5dGt///vdjx44dccstt8SwYcNiwYIFRc+rG8uWLYuurq6YPHlyNDc3R29vb6xYsSLmz59f9LTCNFxgqF1bW1u88cYb8eKLLxY9pa50dHTE4sWL47nnnovhw4cXPadulcvlmDVrVqxcuTIiImbMmBFvvPFGrF+/XmD+jccffzweeeSR2LRpU0ydOjVeffXVWLJkSYwfP/5z+zg1XGBOO+20aG5ujr179x5x/d69e+P0008vaFX9WrRoUTz99NOxdevWAX2bhMFg586dsW/fvpg5c2bfdb29vbF169ZYu3Zt9PT0RHNzc4EL68MZZ5wRU6ZMOeK6c889N37xi18UtKg+3XbbbbFs2bK4/vrrIyJi+vTp8c4770R7e/vnNjAN9xzMsGHD4sILL4wtW7b0XVcul2PLli1xySWXFLisvlQqlVi0aFE88cQT8etf/zomTfIOov/e5ZdfHq+//nq8+uqrfZdZs2bF/Pnz49VXXxWX/2/OnDlVv+K+e/fuOOusswpaVJ8OHjxY9QZczc3NUS7X31t6nygNdwYTEbF06dJYsGBBzJo1Ky666KJYs2ZNHDhwIBYuXFj0tLrR1tYWmzZtiieffDJaW1tjz549EfHxGwW1tLQUvK4+tLa2Vj0nNWLEiBgzZoznqv6NW2+9NS699NJYuXJlfOMb34jt27fHhg0bYsOGDUVPqyvXXHNNrFixIiZOnBhTp06NV155JVavXh033nhj0dOKU2lQ9913X2XixImVYcOGVS666KLKtm3bip5UVyLiUy8PPfRQ0dPq2pe//OXK4sWLi55Rd375y19Wpk2bVimVSpXJkydXNmzYUPSkutPV1VVZvHhxZeLEiZXhw4dXvvjFL1Z+8IMfVHp6eoqeVpiG/H8wANS/hnsOBoDGIDAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKf4faHTiCCnOfI0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.show(plt)\n",
    "wandb.log({\"Confusion Matrix\": wandb.Image(plt)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁</td></tr><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>F1 Score</td><td>▁</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▂▂▂▁▁</td></tr><tr><td>Val Loss</td><td>█▆▄▄▄▂▂▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.53546</td></tr><tr><td>Epoch</td><td>9</td></tr><tr><td>F1 Score</td><td>0.53592</td></tr><tr><td>Train Loss</td><td>1.32911</td></tr><tr><td>Val Loss</td><td>1.28544</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Q2_CNN_AUG</strong> at: <a href='https://wandb.ai/utsv-grg/cv_ass1/runs/c4ilo3pi' target=\"_blank\">https://wandb.ai/utsv-grg/cv_ass1/runs/c4ilo3pi</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240218_230902-c4ilo3pi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training\n",
      "Training for epoch:  0\n",
      "EPOCH: 0\n",
      "Average train loss: 1.2708142879584157\n",
      "EPOCH: 0\n",
      "Average val loss: 1.2571186820665996\n",
      "Training for epoch:  1\n",
      "EPOCH: 1\n",
      "Average train loss: 1.2391011993935768\n",
      "EPOCH: 1\n",
      "Average val loss: 1.190423051516215\n",
      "Training for epoch:  2\n",
      "EPOCH: 2\n",
      "Average train loss: 1.2146516780481271\n",
      "EPOCH: 2\n",
      "Average val loss: 1.22953865925471\n",
      "Training for epoch:  3\n",
      "EPOCH: 3\n",
      "Average train loss: 1.194508287289464\n",
      "EPOCH: 3\n",
      "Average val loss: 1.1734989342235385\n",
      "Training for epoch:  4\n",
      "EPOCH: 4\n",
      "Average train loss: 1.1858295062755018\n",
      "EPOCH: 4\n",
      "Average val loss: 1.1243872784432911\n",
      "Training for epoch:  5\n",
      "EPOCH: 5\n",
      "Average train loss: 1.1477854262429772\n",
      "EPOCH: 5\n",
      "Average val loss: 1.1864720086256664\n",
      "Training for epoch:  6\n",
      "EPOCH: 6\n",
      "Average train loss: 1.1530016189348613\n",
      "EPOCH: 6\n",
      "Average val loss: 1.2255755889983404\n",
      "Training for epoch:  7\n"
     ]
    }
   ],
   "source": [
    "n_epoch = config.epochs\n",
    "save_loss = 99999\n",
    "\n",
    "print(\"Started Training\")\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    print('Training for epoch: ', epoch)\n",
    "\n",
    "    model.train()\n",
    "    tloss = 0\n",
    "    tstep = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        img, label = data\n",
    "        inputs = img.to(device)\n",
    "        labels = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.squeeze(1)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        train_loss =  criterion(outputs, labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        tstep+=1\n",
    "        tloss += train_loss.item()\n",
    "\n",
    "    tstep+=1\n",
    "    print('EPOCH:',epoch)\n",
    "    print('Average train loss:', tloss/tstep)\n",
    "\n",
    "    model.eval()\n",
    "    vloss = 0\n",
    "    vstep = 0\n",
    "\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        img, label = data\n",
    "        inputs = img.to(device)\n",
    "        labels = label.to(device)\n",
    "\n",
    "        inputs = inputs.squeeze(1)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        val_loss =  criterion(outputs, labels)\n",
    "        vstep+=1\n",
    "        vloss += val_loss.item()\n",
    "\n",
    "    vstep+=1\n",
    "    print('EPOCH:',epoch)\n",
    "    print('Average val loss:', vloss/vstep)\n",
    "    if(vloss/vstep<save_loss):\n",
    "        save_loss = vloss/vstep\n",
    "        state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "        torch.save(state, 'q2_cnn_aug_best.pt')  \n",
    "\n",
    "    log_metric = {\"Epoch\":epoch, \"Train Loss\": tloss/tstep, \"Val Loss\": vloss/vstep}\n",
    "    # wandb.log(log_metric)\n",
    "        \n",
    "print(\"Finished Training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
